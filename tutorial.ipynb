{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 给新手的教程：10分钟做一个图像识别程序\n",
    "本教程不讲理只讲操作，力图帮助零基础的同学做出自己的图像识别程序，对于有基础或追求更高目标的同学准备了一些可调参数供你们尝试。\n",
    "\n",
    "| 等级 | 要求 | 通过本教程学到什么 |\n",
    "| - | - | - |\n",
    "| 0 | 会用手机拍视频，会操作电脑 | 傻瓜式地生成一个图像识别程序 |\n",
    "| 1 | 写过Python代码 | 代码写得更好了、学会Keras常用API |\n",
    "| 2 | 理解机器学习及神经网络基本原理 | 学会从零快速构建一个模型和调整参数的方法 |\n",
    "| 3 | 理解卷积神经网络 | 你太优秀了请出去 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1 - 采集数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 用手机拍摄视频记录你想要识别的物体。每段视频中只能包含一种物体，时长10~30秒，每个物体可以拍摄多段视频。视频尽量用4:3或1：1的长宽比，分辨率**低**越好（注意是低）。\n",
    "2. 进入data/video文件夹，为每种物体新建一个文件夹，然后把相应的视频导入进去。例如我拍摄了5段关于猫的视频和3段关于狗的视频，就在data/video文件夹下新建dog、cat两个文件夹，然后把把猫的视频全部放进cat文件夹，把狗的视频全部放进dog文件夹，视频的文件名无所谓。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 - 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一步，我们需要把视频转成图片，然后按照60%、20%、20%的比例拆分成训练集(training set)、验证集(validation set)、和测试集(test set)。\n",
    "\n",
    "为了节省大家时间，我事先已经写好了相关的代码(utils.py)，大家只要按照提示进行调用即可完成这一步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "data\\video\n",
      "共找到15种类别: ['丑', '亥', '写轮眼', '午', '卯', '取消', '子', '寅', '巳', '戌', '未', '申', '空白动作', '辰', '酉']\n",
      "正在处理data\\video\\丑\\chou.mp4\n",
      "正在处理data\\video\\丑\\chou2.mp4\n",
      "正在处理data\\video\\亥\\hai.mp4\n",
      "正在处理data\\video\\写轮眼\\xielunyan.mp4\n",
      "正在处理data\\video\\午\\wu.mp4\n",
      "正在处理data\\video\\卯\\mao.mp4\n",
      "正在处理data\\video\\取消\\cancel.mp4\n",
      "正在处理data\\video\\子\\zi.mp4\n",
      "正在处理data\\video\\寅\\yin.mp4\n",
      "正在处理data\\video\\巳\\si.mp4\n",
      "正在处理data\\video\\戌\\xu.mp4\n",
      "正在处理data\\video\\戌\\xu2.mp4\n",
      "正在处理data\\video\\未\\wei.mp4\n",
      "正在处理data\\video\\未\\wei2.mp4\n",
      "正在处理data\\video\\申\\shen.mp4\n",
      "正在处理data\\video\\申\\shen2.mp4\n",
      "正在处理data\\video\\空白动作\\other.mp4\n",
      "正在处理data\\video\\辰\\chen.mp4\n",
      "正在处理data\\video\\酉\\you.mp4\n",
      "处理完成\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "#################### 以下是你可以修改的部分 ####################\n",
    "fps = 5 # fps是视频的采样率，即每秒中采集多少张图片，建议设置为5~10\n",
    "# 每张图片的大小，根据你原始视频的比例进行缩放，建议不要超过300x300\n",
    "# 训练所需时间会和图像的像素数量成正比，建议设置得小一点，如160x120\n",
    "width = 160\n",
    "height = 90\n",
    "#################### 以上是你可以修改的部分 ####################\n",
    "\n",
    "utils.process_videos(fps, target_size=(width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3 - 数据增强"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把一张原始图片经过拉伸、旋转、斜切、反转等操作，可以生产若干新的不同的图片，用以扩充训练集数据量，有助于提高模型的预测准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1405 images belonging to 15 classes.\n",
      "Found 609 images belonging to 15 classes.\n",
      "Found 578 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "\n",
    "# 设置train，val，test的目录\n",
    "base_dir = Path('data')\n",
    "train_dir = base_dir/'train'\n",
    "val_dir = base_dir/'val'\n",
    "test_dir = base_dir/'test'\n",
    "\n",
    "# 创建train和val图像生成器，它们会不断地产生出新的图片\n",
    "\n",
    "#################### 以下是你可以修改的部分 ####################\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=False,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "#################### 以上是你可以修改的部分 ####################\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(height,width))\n",
    "val_generator = train_datagen.flow_from_directory(val_dir, target_size=(height,width))\n",
    "\n",
    "# test的时候是模拟真实环境，所以要使用原始图片，不要对图片进行任何操作\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(height,width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4 - 搭建卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一步我们要搭建神经网络的架构。\n",
    "\n",
    "图像识别的常见方法是通过卷积操作提取图片中的特征，然后将特征输入到神经网络中，最后神经网络输出结果。所以在这一阶段，我们要分别准备卷积和神经网络两个部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - 卷积部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迁移学习(transfer learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对图像进行卷积操作需要耗费大量计算资源，并且训练需要巨大的数据量，一般个人是搞不定这事的。\n",
    "\n",
    "好消息是人们发现了一个有趣的现象：训练出来用于识别A物体的卷积神经网络，它的卷积部分也能够很好地被用于识别B物体。\n",
    "\n",
    "所以我们可以把人家已经训练好的NB的卷积神经网络借来用，这就是迁移学习。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16是一个非常经典的卷积神经网络，16代表有16个层，前13层是卷积层，后3层是全连阶层。我们需要使用它的前13个卷积层，并且使用这些层的权值，用来从图像中提取特征。然后把提取后的特征输入到我们自己的神经网络中进行识别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per-trained model has been loaded\n"
     ]
    }
   ],
   "source": [
    "import keras as K\n",
    "\n",
    "# load pretrained model and weights\n",
    "conv_layers = K.applications.VGG16(include_top=False, input_shape=(height,width,3))\n",
    "conv_layers.trainable = False\n",
    "print('per-trained model has been loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了VGG16以外还有很多更[先进的模型](https://keras.io/applications/)，你可以尝试更换不同的模型看看哪个效果更好。\n",
    "\n",
    "|Model|\tSize|Top-1 Accuracy|Top-5 Accuracy|Parameters|Depth|\n",
    "|-|-|-|-|-|\n",
    "|Xception|88 MB|0.790|0.945|22,910,480|126|\n",
    "|VGG16|528 MB|0.715|0.901|138,357,544|23|\n",
    "|VGG19|549 MB|0.727|0.910|143,667,240|26|\n",
    "|ResNet50|99 MB|0.759|0.929|25,636,712|168|\n",
    "|InceptionV3\t|92 MB\t|0.788\t|0.944\t|23,851,784\t|159|\n",
    "|InceptionResNetV2\t|215 MB\t|0.804\t|0.953\t|55,873,736\t|572|\n",
    "|MobileNet\t|17 MB\t|0.665\t|0.871\t|4,253,864\t|88|\n",
    "|DenseNet121\t|33 MB\t|0.745\t|0.918\t|8,062,504|\t121|\n",
    "|DenseNet169\t|57 MB\t|0.759\t|0.928\t|14,307,880\t|169|\n",
    "|DenseNet201\t|80 MB\t|0.770\t|0.933\t|20,242,984\t|201|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - 神经网络部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下是神经网络的架构：\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 5, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              10487808  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                30735     \n",
      "=================================================================\n",
      "Total params: 29,429,583\n",
      "Trainable params: 14,714,895\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = K.models.Sequential()\n",
    "model.add(conv_layers)#载入VGG16的卷积部分\n",
    "model.add(K.layers.Flatten())#拉平成一维\n",
    "n_classes = len(utils.get_child_dir_names(base_dir/'video'))\n",
    "\n",
    "# 以下是你可以修改的部分\n",
    "model.add(K.layers.Dense(2048, activation='relu'))\n",
    "model.add(K.layers.Dropout(0.5))\n",
    "model.add(K.layers.Dense(2048, activation='relu'))\n",
    "model.add(K.layers.Dropout(0.5))\n",
    "# 以上是你可以修改的部分\n",
    "\n",
    "model.add(K.layers.Dense(n_classes, activation='softmax')) \n",
    "print('以下是神经网络的架构：')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step5 - 训练及验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以尝试选择不同的优化器和优化器参数（[Keras文档](http://keras-cn.readthedocs.io/en/latest/other/optimizers/)），好的优化器能让训练结果尽快收敛并获得更高的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "优化器设置完毕\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print('优化器设置完毕')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始训练，为了节省时间只设置了迭代20次。你可以尝试不同迭代次看看它数对最终结果的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "n_train_samples = utils.count_jpgs(train_dir)#训练集图片总数\n",
    "n_val_samples = utils.count_jpgs(val_dir)#val集图片总数\n",
    "batch_size = 32\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=n_train_samples/batch_size, epochs=n_epochs, \n",
    "                              validation_data=val_generator, validation_steps=n_val_samples/batch_size, verbose=2)\n",
    "print('训练完毕')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画图看一下训练效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(8,4), dpi=100)\n",
    "plt.plot(range(n_epochs), history.history['acc'], 'c', label='Training Accuracy', aa=True)\n",
    "plt.plot(range(n_epochs), history.history['val_acc'], 'darkorange', label='Validation Accuracy', aa=True)\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 怎么看训练的结果好不好\n",
    "### 好的情况\n",
    "总体上来看，train和val的正确率都随着迭代次数增加而上升，并且最后收敛于某一个比较高的数值。\n",
    "### 两种不好的情况\n",
    "1. 欠拟合（under-fitting）\n",
    "\n",
    "train和val的正确率都比较低。\n",
    "造成这种情况的原因有很多，常见的有：数据量不够大、神经网络设计得不合理、优化器选择不合理、迭代次数不够\n",
    "2. 过拟合（over-fitting）\n",
    "\n",
    "train的正确率很高，但是val正确率很低。\n",
    "这种情况代表模型的泛化能力不好，它完全适应了训练集的数据（可以接近100%的正确率），但是不适用于验证集的数据。\n",
    "解决方法是使用在Dense层后追加[Dropout层](https://keras-cn.readthedocs.io/en/latest/layers/core_layer/#dropout)或是在Densse层的选项中设置[regularizer](http://keras-cn.readthedocs.io/en/latest/other/regularizers/)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step6 - 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果上面的验证结果还不错，那恭喜你就快要成功了！\n",
    "最后我们用测试集的数据来测试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_test_samples = utils.count_jpgs(test_dir)\n",
    "_, test_acc = model.evaluate_generator(test_generator, steps=n_test_samples/batch_size)\n",
    "print('测试正确率：{}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step7 - 拍张照，让程序来判断它是什么"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拍一张照，上传到 data/x 文件夹中，默认文件名是 myimage.jpg。如果你保存了其它文件名或是其它文件夹，需要修改下方代码中的路径。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先显示一下图片看看对不对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "path = 'data/test/辰/chen_0.jpg'\n",
    "img = Image.open(path)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 让程序来预测试试吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = utils.preprocess(img, (width, height))\n",
    "y = model.predict(x)[0]\n",
    "class_indices = train_generator.class_indices#获得文件夹名的和类的序号对应的字典\n",
    "class_indices_reverse={v:k for k,v in class_indices.items()}#反转字典的索引和内容值\n",
    "\n",
    "utils.show_pred(y,class_indices_reverse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional - 用自己电脑的摄像头做实时预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先保存训练好的模型文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save('model/NARUTO.h5')\n",
    "utils.save_confg(class_indices_reverse,input_size=(160,90),fp='model/config.json')\n",
    "print('保存成功')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后运行其中model文件夹下的的predict.py即可。 \n",
    "\n",
    "这里有个注意事项：我用的vscode编辑器来运行predict.py，把当前工作路径设置为 NARUTO_game 这个主文件夹，并以此设置相关的相对路径，若直接cd到model文件夹来运行predict.py文件，需要手动调整源码中的相对路径"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
